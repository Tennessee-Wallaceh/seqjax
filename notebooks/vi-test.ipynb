{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "482b0757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "LOG_2PI = jnp.log(2.0 * jnp.pi)\n",
    "\n",
    "def kl_diag_standard_normal(mu, log_sigma):\n",
    "    sigma2 = jnp.exp(2.0 * log_sigma)\n",
    "    return 0.5 * jnp.sum(sigma2 + mu**2 - 2.0 * log_sigma - 1.0)\n",
    "\n",
    "def mc_neg_elbo(key, mu, log_sigma, num_mc: int):\n",
    "    d = mu.shape[0]\n",
    "    eps = jax.random.normal(key, shape=(num_mc, d))\n",
    "    sigma = jnp.exp(log_sigma)\n",
    "    z = mu[None, :] + sigma[None, :] * eps\n",
    "\n",
    "    logp = -0.5 * jnp.sum(z**2, axis=-1) - 0.5 * d * LOG_2PI\n",
    "    logq = -0.5 * jnp.sum(eps**2, axis=-1) - jnp.sum(log_sigma) - 0.5 * d * LOG_2PI\n",
    "    return -jnp.mean(logp - logq)\n",
    "\n",
    "@partial(jax.jit, static_argnames=(\"optimizer\",))\n",
    "def step_exact(opt_state, params, optimizer):\n",
    "    mu, log_sigma = params\n",
    "    loss, grads = jax.value_and_grad(kl_diag_standard_normal, argnums=(0, 1))(mu, log_sigma)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return opt_state, params, loss\n",
    "\n",
    "@partial(jax.jit, static_argnames=(\"optimizer\", \"num_mc\"))\n",
    "def step_mc(key, opt_state, params, optimizer, num_mc: int):\n",
    "    mu, log_sigma = params\n",
    "    key, subkey = jax.random.split(key)\n",
    "\n",
    "    def loss_fn(mu_, log_sigma_):\n",
    "        return mc_neg_elbo(subkey, mu_, log_sigma_, num_mc)\n",
    "\n",
    "    loss, grads = jax.value_and_grad(loss_fn, argnums=(0, 1))(mu, log_sigma)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return key, opt_state, params, loss\n",
    "\n",
    "\n",
    "def run(mode: str = \"mc\", seed: int = 0, d: int = 100, steps: int = 2000,\n",
    "        lr: float = 1e-2, num_mc: int = 8, init_log_sigma: float = -2.0, log_every: int = 200):\n",
    "    \"\"\"\n",
    "    mode: \"exact\" or \"mc\"\n",
    "    \"\"\"\n",
    "    key = jax.random.key(seed)\n",
    "\n",
    "    mu = jnp.zeros((d,))\n",
    "    log_sigma = jnp.ones((d,)) * init_log_sigma\n",
    "    params = (mu, log_sigma)\n",
    "\n",
    "    optimizer = optax.adam(lr)\n",
    "    opt_state = optimizer.init(params)\n",
    "\n",
    "    means = []\n",
    "    stds = []\n",
    "    ts = []\n",
    "    for t in range(1, steps + 1):\n",
    "        if mode == \"exact\":\n",
    "            opt_state, params, loss = step_exact(opt_state, params, optimizer)\n",
    "        elif mode == \"mc\":\n",
    "            key, opt_state, params, loss = step_mc(key, opt_state, params, optimizer, num_mc)\n",
    "        else:\n",
    "            raise ValueError(\"mode must be 'exact' or 'mc'\")\n",
    "\n",
    "        if (t % log_every) == 0 or t == 1:\n",
    "            mu, log_sigma = params\n",
    "            sigma = jnp.exp(log_sigma)\n",
    "            kl = kl_diag_standard_normal(mu, log_sigma)\n",
    "            print(\n",
    "                f\"t={t:5d}  loss={float(loss): .6f}  KL={float(kl): .6f}  \"\n",
    "                f\"|mu|={float(jnp.linalg.norm(mu)):.4f}  \"\n",
    "                f\"mean(sigma)={float(jnp.mean(sigma)):.4f}  std(sigma)={float(jnp.std(sigma)):.4f}  \"\n",
    "                f\"min(sigma)={float(jnp.min(sigma)):.4e}\"\n",
    "            )\n",
    "            means.append(jnp.mean(sigma))\n",
    "            stds.append(jnp.std(sigma))\n",
    "            ts.append(t)\n",
    "\n",
    "    return params, means, stds, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e1b9515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=    1  loss= 250.123932  KL= 245.136993  |mu|=0.0000  mean(sigma)=0.0523  std(sigma)=0.0000  min(sigma)=5.2340e-02\n",
      "t=  200  loss= 0.000006  KL= 0.000006  |mu|=0.0000  mean(sigma)=0.9998  std(sigma)=0.0000  min(sigma)=9.9983e-01\n",
      "t=  400  loss= 0.000000  KL= 0.000000  |mu|=0.0000  mean(sigma)=1.0000  std(sigma)=0.0000  min(sigma)=1.0000e+00\n",
      "t=  600  loss=-0.000003  KL=-0.000003  |mu|=0.0000  mean(sigma)=1.0000  std(sigma)=0.0000  min(sigma)=1.0000e+00\n",
      "t=  800  loss=-0.000003  KL=-0.000003  |mu|=0.0000  mean(sigma)=1.0000  std(sigma)=0.0000  min(sigma)=1.0000e+00\n",
      "t= 1000  loss=-0.000003  KL=-0.000003  |mu|=0.0000  mean(sigma)=1.0000  std(sigma)=0.0000  min(sigma)=1.0000e+00\n",
      "t= 1200  loss=-0.000003  KL=-0.000003  |mu|=0.0000  mean(sigma)=1.0000  std(sigma)=0.0000  min(sigma)=1.0000e+00\n",
      "t= 1400  loss=-0.000003  KL=-0.000003  |mu|=0.0000  mean(sigma)=1.0000  std(sigma)=0.0000  min(sigma)=1.0000e+00\n",
      "t= 1600  loss=-0.000003  KL=-0.000003  |mu|=0.0000  mean(sigma)=1.0000  std(sigma)=0.0000  min(sigma)=1.0000e+00\n",
      "t= 1800  loss=-0.000003  KL=-0.000003  |mu|=0.0000  mean(sigma)=1.0000  std(sigma)=0.0000  min(sigma)=1.0000e+00\n",
      "t= 2000  loss=-0.000003  KL=-0.000003  |mu|=0.0000  mean(sigma)=1.0000  std(sigma)=0.0000  min(sigma)=1.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],      dtype=float32),\n",
       " Array([1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08,\n",
       "        1.6452576e-08, 1.6452576e-08, 1.6452576e-08, 1.6452576e-08],      dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity: exact optimization should nail sigma ~ 1 quickly from almost any init.\n",
    "run(mode=\"exact\", seed=0, d=100, steps=2000, lr=5e-2, init_log_sigma=-3.0, log_every=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d247735a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=    1  loss= 247.486664  KL= 245.261993  |mu|=0.5000  mean(sigma)=0.0523  std(sigma)=0.0000  min(sigma)=5.2340e-02\n",
      "t= 1000  loss= 0.192264  KL= 0.468204  |mu|=0.5972  mean(sigma)=0.9942  std(sigma)=0.0534  min(sigma)=8.6873e-01\n",
      "t= 2000  loss= 0.876277  KL= 0.541946  |mu|=0.7078  mean(sigma)=1.0031  std(sigma)=0.0542  min(sigma)=8.9238e-01\n",
      "t= 3000  loss= 0.530626  KL= 0.421085  |mu|=0.5891  mean(sigma)=0.9875  std(sigma)=0.0478  min(sigma)=8.7415e-01\n",
      "t= 4000  loss= 0.397608  KL= 0.446191  |mu|=0.6177  mean(sigma)=1.0044  std(sigma)=0.0503  min(sigma)=8.5669e-01\n",
      "t= 5000  loss= 0.617996  KL= 0.552384  |mu|=0.6356  mean(sigma)=1.0020  std(sigma)=0.0593  min(sigma)=8.6286e-01\n",
      "t= 6000  loss= 0.483220  KL= 0.488588  |mu|=0.6183  mean(sigma)=0.9901  std(sigma)=0.0534  min(sigma)=8.5783e-01\n",
      "t= 7000  loss= 0.482189  KL= 0.475805  |mu|=0.6490  mean(sigma)=0.9951  std(sigma)=0.0512  min(sigma)=8.8723e-01\n",
      "t= 8000  loss= 0.461131  KL= 0.519379  |mu|=0.6794  mean(sigma)=1.0065  std(sigma)=0.0536  min(sigma)=8.7039e-01\n",
      "t= 9000  loss= 0.157965  KL= 0.481968  |mu|=0.5899  mean(sigma)=1.0097  std(sigma)=0.0549  min(sigma)=8.6961e-01\n",
      "t=10000  loss= 0.735687  KL= 0.446765  |mu|=0.6077  mean(sigma)=0.9963  std(sigma)=0.0510  min(sigma)=8.8131e-01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array([ 0.05222048, -0.09547757, -0.08973138, -0.00486247, -0.06041062,\n",
       "        -0.05572452,  0.00952461, -0.00474449,  0.01430413, -0.01745423,\n",
       "         0.00565786,  0.08210675,  0.02284317,  0.05148947, -0.055523  ,\n",
       "         0.07317773,  0.00569338,  0.01393594,  0.01632994,  0.10512311,\n",
       "         0.0303864 ,  0.08212869, -0.1063923 ,  0.08140229, -0.05069764,\n",
       "        -0.01297907, -0.07561885, -0.08708009,  0.08924918,  0.05945631,\n",
       "         0.0725781 , -0.01374277,  0.01198772,  0.01489643, -0.01569547,\n",
       "         0.08592975,  0.00278923, -0.05594056, -0.04632309,  0.12979361,\n",
       "         0.01708827,  0.13152191, -0.02218023, -0.03593712, -0.02776361,\n",
       "        -0.02619023,  0.02860598, -0.11970337, -0.04563605,  0.10448401,\n",
       "         0.00321919, -0.04123145, -0.02309494,  0.02316009, -0.05259848,\n",
       "         0.03408407,  0.00239959, -0.03576782,  0.01027049, -0.07080129,\n",
       "         0.03262068, -0.05093395,  0.03949349,  0.03585717, -0.12591767,\n",
       "        -0.06085879, -0.09696774, -0.03278483, -0.05123695, -0.02522749,\n",
       "        -0.05918833,  0.10814613, -0.00406938, -0.11927468, -0.09165664,\n",
       "         0.03156049, -0.01245068, -0.07709859,  0.03947926,  0.04136704,\n",
       "         0.01576799,  0.02239375,  0.03428152, -0.00534198, -0.0584483 ,\n",
       "        -0.09784669, -0.05059843,  0.0168235 ,  0.04105836, -0.02250335,\n",
       "        -0.04828456, -0.02141809,  0.10157035,  0.11086979,  0.07449034,\n",
       "         0.05988513, -0.01736482, -0.11800937, -0.05510754,  0.03837373],      dtype=float32),\n",
       " Array([-0.06492881,  0.01399274, -0.01162304,  0.01416143, -0.01791796,\n",
       "        -0.03261773,  0.0097391 ,  0.0912222 ,  0.02406257, -0.08530686,\n",
       "         0.08451872, -0.04108866,  0.0025171 ,  0.00700944, -0.0200729 ,\n",
       "        -0.01950444,  0.01664223,  0.01973091,  0.04303387, -0.11592226,\n",
       "         0.03561876,  0.01747049, -0.00440742, -0.01249214,  0.07185603,\n",
       "         0.05368375, -0.07821899, -0.0456395 , -0.072924  ,  0.00876376,\n",
       "        -0.05003883, -0.05166657, -0.0242564 ,  0.00440248, -0.01668159,\n",
       "         0.07855386, -0.02286158,  0.05642087,  0.0136446 , -0.00703363,\n",
       "        -0.00301457,  0.11475791,  0.07459329, -0.01962815, -0.00965868,\n",
       "         0.05713408,  0.01301356, -0.00164061, -0.00188984,  0.02265726,\n",
       "        -0.07628056, -0.0286162 ,  0.00864139, -0.06196832,  0.0541059 ,\n",
       "        -0.02810661, -0.03734513, -0.05190979,  0.02450983,  0.07974245,\n",
       "         0.05159228,  0.00080771, -0.04247285,  0.08008649, -0.01423798,\n",
       "        -0.07054818, -0.02850361, -0.01880673,  0.12252439, -0.00578758,\n",
       "        -0.01574269,  0.01532581,  0.06167939,  0.01078717,  0.01715674,\n",
       "         0.03684274, -0.02169897,  0.02757033, -0.12635063, -0.05599266,\n",
       "         0.05705442,  0.04173086, -0.10677101, -0.07682112, -0.02484968,\n",
       "        -0.05954891,  0.04268811, -0.08065864,  0.04026287, -0.02212354,\n",
       "        -0.08725237, -0.00750624, -0.04904601, -0.02344234, -0.05742196,\n",
       "        -0.01266935, -0.01016839,  0.06434758, -0.05825254, -0.10081147],      dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MC: should work with reasonable settings.\n",
    "\n",
    "run(mode=\"mc\", seed=0, d=100, steps=10000, lr=5e-2, num_mc=32, init_log_sigma=-3.0, log_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8301454a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=    1  loss= 246.082306  KL= 232.184998  |mu|=2.0000  mean(sigma)=0.0608  std(sigma)=0.0000  min(sigma)=6.0810e-02\n",
      "t=  200  loss= 8.199280  KL= 11.450817  |mu|=3.0370  mean(sigma)=0.9815  std(sigma)=0.2500  min(sigma)=3.7768e-01\n",
      "t=  400  loss= 8.570023  KL= 12.263913  |mu|=3.1032  mean(sigma)=0.9925  std(sigma)=0.2690  min(sigma)=3.8712e-01\n",
      "t=  600  loss= 4.533768  KL= 11.666977  |mu|=3.2454  mean(sigma)=0.9606  std(sigma)=0.2394  min(sigma)=3.3763e-01\n",
      "t=  800  loss= 8.456177  KL= 12.849049  |mu|=3.1989  mean(sigma)=1.0054  std(sigma)=0.2809  min(sigma)=5.6365e-01\n",
      "t= 1000  loss= 18.115662  KL= 16.669365  |mu|=3.3841  mean(sigma)=1.0090  std(sigma)=0.3383  min(sigma)=3.6990e-01\n",
      "t= 1200  loss= 24.594284  KL= 15.183155  |mu|=2.8522  mean(sigma)=0.9744  std(sigma)=0.3180  min(sigma)=2.1452e-01\n",
      "t= 1400  loss= 14.525162  KL= 12.611357  |mu|=2.9606  mean(sigma)=0.9385  std(sigma)=0.2665  min(sigma)=2.1321e-01\n",
      "t= 1600  loss= 17.679977  KL= 13.534353  |mu|=2.8683  mean(sigma)=0.9475  std(sigma)=0.2816  min(sigma)=2.4953e-01\n",
      "t= 1800  loss= 21.006729  KL= 13.709188  |mu|=3.5499  mean(sigma)=0.9477  std(sigma)=0.2613  min(sigma)=4.4443e-01\n",
      "t= 2000  loss= 19.711044  KL= 14.129701  |mu|=2.9530  mean(sigma)=0.9850  std(sigma)=0.3064  min(sigma)=2.8949e-01\n",
      "t= 2200  loss= 8.831741  KL= 10.701900  |mu|=2.7889  mean(sigma)=1.0097  std(sigma)=0.2599  min(sigma)=3.5571e-01\n",
      "t= 2400  loss= 7.380417  KL= 12.187590  |mu|=2.8941  mean(sigma)=0.9890  std(sigma)=0.2716  min(sigma)=2.7866e-01\n",
      "t= 2600  loss= 1.761185  KL= 12.705141  |mu|=3.2850  mean(sigma)=0.9561  std(sigma)=0.2591  min(sigma)=4.4288e-01\n",
      "t= 2800  loss= 3.599106  KL= 10.681157  |mu|=2.9467  mean(sigma)=0.9787  std(sigma)=0.2423  min(sigma)=3.9192e-01\n",
      "t= 3000  loss= 13.057785  KL= 12.124179  |mu|=2.9732  mean(sigma)=0.9600  std(sigma)=0.2690  min(sigma)=4.1842e-01\n",
      "t= 3200  loss= 15.477936  KL= 13.380820  |mu|=3.1818  mean(sigma)=0.9912  std(sigma)=0.2856  min(sigma)=3.8474e-01\n",
      "t= 3400  loss= 16.848114  KL= 16.253571  |mu|=3.2355  mean(sigma)=0.9716  std(sigma)=0.3048  min(sigma)=1.2004e-01\n",
      "t= 3600  loss= 15.413605  KL= 11.519524  |mu|=2.7924  mean(sigma)=0.9802  std(sigma)=0.2720  min(sigma)=5.1544e-01\n",
      "t= 3800  loss= 15.092133  KL= 13.436579  |mu|=3.4146  mean(sigma)=0.9762  std(sigma)=0.2696  min(sigma)=3.6524e-01\n",
      "t= 4000  loss= 10.425537  KL= 13.678729  |mu|=3.1381  mean(sigma)=0.9318  std(sigma)=0.2719  min(sigma)=3.3667e-01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array([ 0.26047188, -0.37172276,  0.00252672, -0.19129899, -0.20676397,\n",
       "        -0.7970484 , -0.29160658, -0.06943002, -0.44504952, -0.08637094,\n",
       "         0.18900146, -0.20127475, -0.38819084,  0.07795054, -0.4408967 ,\n",
       "        -0.14589953, -0.04657221, -0.06250014,  0.3746062 , -0.34293354,\n",
       "        -0.21741675, -0.17951053,  0.22295861, -0.4065317 ,  0.00509515,\n",
       "        -0.00165432, -0.5605479 , -0.64103186, -0.29320174,  0.28177407,\n",
       "        -0.44035345, -0.06821295,  0.6495677 , -0.2204929 , -0.3080792 ,\n",
       "        -0.00634776,  0.09931718, -0.05755906, -0.20617934,  0.3373213 ,\n",
       "         0.0447189 ,  0.22640753, -0.13294555, -0.7889059 ,  0.01509628,\n",
       "        -0.23003182,  0.16644815,  0.1881523 , -0.17196876, -0.23686506,\n",
       "        -0.05457807,  0.22352776, -0.13154888, -0.09709449, -0.16866939,\n",
       "         0.1696515 ,  0.29132098, -0.7004078 ,  0.04433437, -0.40666303,\n",
       "         0.18765667,  0.4787695 ,  0.16759159,  0.11209597, -0.436815  ,\n",
       "         0.29356977, -0.24123292, -0.40653935,  0.04860381, -0.2910713 ,\n",
       "         0.36277443, -0.12632741, -0.10901301, -0.40728736,  0.5004437 ,\n",
       "         0.43204105,  0.45467734,  0.21232831,  0.4418006 , -0.640372  ,\n",
       "        -0.57270205, -0.17272033,  0.13158257,  0.04775213,  0.5339482 ,\n",
       "         0.11286806, -0.02038873,  0.00488321, -0.18977608,  0.43730527,\n",
       "        -0.06872129, -0.3891676 , -0.03262373,  0.52931005,  0.07800977,\n",
       "         0.09170803, -0.0069674 ,  0.05128852,  0.2828241 , -0.27492556],      dtype=float32),\n",
       " Array([ 0.1424458 ,  0.10826886, -0.28634775, -0.18263316,  0.22204812,\n",
       "        -0.1661278 , -1.0009924 , -0.02949191, -0.5188526 , -0.2679212 ,\n",
       "        -0.15862635, -0.06156593,  0.29883882,  0.09357639, -0.59092945,\n",
       "         0.11367609, -0.37218666,  0.17600046, -0.02252931, -0.2204919 ,\n",
       "        -0.5493384 , -0.00295264,  0.27881584, -0.07293858, -0.02446804,\n",
       "        -0.01287588,  0.08980328,  0.0271779 , -0.2502838 , -0.26482078,\n",
       "        -0.6076908 ,  0.10477588,  0.1928114 , -0.05384864,  0.12902805,\n",
       "        -0.16565503,  0.09297206, -0.07979895, -0.10255913, -0.06682317,\n",
       "         0.12472759, -0.02366923, -1.0886655 , -0.10120739, -0.19706194,\n",
       "         0.2778491 ,  0.00808262,  0.05423388, -0.48608515, -0.1008484 ,\n",
       "         0.20316495,  0.01981678,  0.17659193, -0.02470197, -0.17089185,\n",
       "        -0.16616881,  0.4832746 , -0.00214617,  0.20966378, -0.28680104,\n",
       "         0.12888388,  0.02908636,  0.2860465 , -0.00829973,  0.18678732,\n",
       "        -0.24509028, -0.0969447 , -0.0564305 , -0.39919862,  0.17880419,\n",
       "         0.7139021 , -0.8506275 , -0.14203623,  0.14395605, -0.36357036,\n",
       "        -0.12287189, -0.31177807, -1.0842198 , -0.3320807 , -0.46637338,\n",
       "        -0.08463491, -0.23436636, -0.32021648, -0.05049745,  0.05734947,\n",
       "        -0.4374414 , -0.20216528,  0.09769814, -0.2679217 , -0.22064333,\n",
       "         0.25134897, -0.01192576, -0.874414  , -0.7797709 ,  0.463663  ,\n",
       "        -0.29247653, -0.2166377 , -0.25876176, -0.28427574, -0.0171319 ],      dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MC stress test: tiny num_mc + big lr can produce bad dynamics (often looks like “collapse”).\n",
    "run(mode=\"mc\", seed=0, d=100, steps=4000, lr=2e-1, num_mc=1, init_log_sigma=-3.0, log_every=200)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seqjax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
